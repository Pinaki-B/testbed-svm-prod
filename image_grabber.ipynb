{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "import random\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 #Currently unused\n",
    "from skimage.feature import hog #Need to install scikit-image for this -- ended up using HOG from here\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "test_apple_dir = \"model_data/Test/Apples\"\n",
    "test_orange_dir = \"model_data/Test/Oranges\"\n",
    "\n",
    "train_apple_dir = \"model_data/Train/Apples\"\n",
    "train_orange_dir = \"model_data/Train/Oranges\"\n",
    "\n",
    "RAW_DATASET_PATH = \"raw_dataset\"\n",
    "RAW_TRAIN_DATASET_PATH = os.path.join(RAW_DATASET_PATH, \"Training\")\n",
    "RAW_TEST_DATASET_PATH = os.path.join(RAW_DATASET_PATH, \"Test\")\n",
    "DATASET_PATH = \"model_data\"\n",
    "TRAIN_DATASET_PATH = os.path.join(DATASET_PATH, \"Train\")\n",
    "TEST_DATASET_PATH = os.path.join(DATASET_PATH, \"Test\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# ONLY RUN CELL IF NEEDED TO CLEAR ALL THE MODEL_DATA\n",
    "print(os.getcwd())\n",
    "\n",
    "if os.path.exists(test_apple_dir):\n",
    "    shutil.rmtree(test_apple_dir)\n",
    "\n",
    "if os.path.exists(test_orange_dir):\n",
    "    shutil.rmtree(test_orange_dir)\n",
    "\n",
    "if os.path.exists(train_apple_dir):\n",
    "    shutil.rmtree(train_apple_dir)\n",
    "\n",
    "if os.path.exists(train_orange_dir):\n",
    "    shutil.rmtree(train_orange_dir)\n",
    "\n",
    "if os.path.exists(\"model_data/TestBinaries/Apples\"):\n",
    "    shutil.rmtree(\"model_data/TestBinaries/Apples\")\n",
    "if os.path.exists(\"model_data/TestBinaries/Oranges\"):\n",
    "    shutil.rmtree(\"model_data/TestBinaries/Oranges\")\n",
    "\n",
    "os.mkdir(test_apple_dir)\n",
    "os.mkdir(test_orange_dir)\n",
    "os.mkdir(train_apple_dir)\n",
    "os.mkdir(train_orange_dir)\n",
    "os.mkdir(\"model_data/TestBinaries/Oranges\")\n",
    "os.mkdir(\"model_data/TestBinaries/Apples\")\n",
    "\n",
    "if (os.path.isfile(os.path.join(TRAIN_DATASET_PATH, \"apple_out.csv\"))):\n",
    "    os.remove(os.path.join(TRAIN_DATASET_PATH, \"apple_out.csv\"))\n",
    "\n",
    "if (os.path.isfile(os.path.join(TRAIN_DATASET_PATH, \"orange_out.csv\"))):\n",
    "    os.remove(os.path.join(TRAIN_DATASET_PATH, \"orange_out.csv\"))\n",
    "\n",
    "if os.path.isfile(\"model.h\"):\n",
    "    os.remove(\"model.h\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/pbhagava/Desktop/EdgeTestbed/edge_testbed/V1/src/sw/test_images\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "def copyImages(directory, destination, num_files=-1):\n",
    "    files = os.listdir(directory)\n",
    "    ret = 0\n",
    "    if num_files == -1:\n",
    "        ret = files\n",
    "    else:\n",
    "        ret = random.sample(files, num_files)\n",
    "    for fl in ret:\n",
    "        path = os.path.join(directory, fl)\n",
    "        shutil.copy(path, destination)\n",
    "    return ret\n",
    "\n",
    "apple_names = [\"Apple Red 1\"]\n",
    "\n",
    "#Generate Train Image Set\n",
    "orange_files = copyImages(os.path.join(RAW_TRAIN_DATASET_PATH, \"Orange\"), os.path.join(TRAIN_DATASET_PATH, \"Oranges\"))\n",
    "NUM_ORANGE_IMAGES = len(orange_files)\n",
    "NUM_APPLE_IMAGES_PER_APPLE = NUM_ORANGE_IMAGES // len(apple_names)\n",
    "for apple_type in apple_names:\n",
    "    copyImages(os.path.join(RAW_TRAIN_DATASET_PATH, apple_type), os.path.join(TRAIN_DATASET_PATH, \"Apples\"), NUM_APPLE_IMAGES_PER_APPLE)\n",
    "print(\"Generated training set!\")\n",
    "print(f\"Number of Orange images: {NUM_ORANGE_IMAGES}\")\n",
    "print(f\"Number of Apple images: {NUM_APPLE_IMAGES_PER_APPLE * len(apple_names)} | {NUM_APPLE_IMAGES_PER_APPLE} images per apple type\")\n",
    "\n",
    "#Generate Test Image Set\n",
    "orange_test_files = copyImages(os.path.join(RAW_TEST_DATASET_PATH, \"Orange\"), os.path.join(TEST_DATASET_PATH, \"Oranges\"))\n",
    "NUM_TEST_ORANGE_IMAGES = len(orange_test_files)\n",
    "NUM_APPLE_TEST_IMAGES_PER_APPLE = NUM_TEST_ORANGE_IMAGES // len(apple_names)\n",
    "for apple_type in apple_names:\n",
    "    copyImages(os.path.join(RAW_TEST_DATASET_PATH, apple_type), os.path.join(TEST_DATASET_PATH, \"Apples\"), NUM_APPLE_TEST_IMAGES_PER_APPLE)\n",
    "print(\"\\nGenerated testing set!\")\n",
    "print(f\"Number of Orange images: {NUM_TEST_ORANGE_IMAGES}\")\n",
    "print(f\"Number of Apple images: {NUM_APPLE_TEST_IMAGES_PER_APPLE * len(apple_names)} | {NUM_APPLE_TEST_IMAGES_PER_APPLE} images per apple type\")\n",
    "print(f\"Total number of test images: {NUM_APPLE_TEST_IMAGES_PER_APPLE * len(apple_names) + NUM_TEST_ORANGE_IMAGES}\")\n",
    "\n",
    "#Generate Test Binaries Set \n",
    "def generate_binaries(dir, fruit, dest):\n",
    "    files = os.listdir(dir)\n",
    "    for n, fl in enumerate(files):\n",
    "        pth = os.path.join(dir, fl)\n",
    "        dst = os.path.join(dest, f\"{fruit}-{n}.txt\")\n",
    "        os.system(f'ffmpeg -i {pth} -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e \\'1/2 \"%u \" \"\\\\n\"\\' -v > {dst}')\n",
    "    return\n",
    "\n",
    "generate_binaries(test_orange_dir, \"orange\", \"model_data/TestBinaries/Oranges\")\n",
    "generate_binaries(test_apple_dir, \"apple\", \"model_data/TestBinaries/Apples\")\n",
    "print(\"\\nGenerated Test Binaries!\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generated training set!\n",
      "Number of Orange images: 479\n",
      "Number of Apple images: 479 | 479 images per apple type\n",
      "\n",
      "Generated testing set!\n",
      "Number of Orange images: 160\n",
      "Number of Apple images: 160 | 160 images per apple type\n",
      "Total number of test images: 320\n",
      "\n",
      "Generated Test Binaries!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "source": [
    "# Upscale/Rescale Images to 320x240\n",
    "def convertTo320x240(dir, verbose=False):\n",
    "    files = os.listdir(dir)\n",
    "    for n, fl in enumerate(files):\n",
    "        pth = os.path.join(dir, fl)\n",
    "        dst = os.path.join(dir, f\"resized-{fl}\")\n",
    "        os.system(f\"convert {pth} -resize 320x240 -background white -gravity center -extent 320x240 {dst}\")\n",
    "        if verbose:\n",
    "            print(f\"ran convert {pth} -resize 320x240 -background white -gravity center -extent 320x240 {dst}\")\n",
    "    return\n",
    "\n",
    "convertTo320x240(test_apple_dir)\n",
    "convertTo320x240(test_orange_dir)\n",
    "convertTo320x240(train_apple_dir)\n",
    "convertTo320x240(train_orange_dir)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "source": [
    "# str_ = 'ffmpeg -i converted-230_100.jpg -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e \\'1/2 \"%u \" \"\\\\n\"\\' -v > test.txt'\n",
    "# print(str_)\n",
    "# \n",
    "# ffmpeg -i converted-230_100.jpg -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e '1/2 \"%u \" \"\\n\"' -v > test.txt\n",
    "\n",
    "def convertTo565(dir, fruit, to_csv=False, verbose=False):\n",
    "    files = os.listdir(dir)\n",
    "    for n, fl in enumerate(files):\n",
    "        pth = os.path.join(dir, fl)\n",
    "        dst = os.path.join(dir, f\"565-{fruit}-{n}.jpg\")\n",
    "        \n",
    "        os.system(f'convert {pth} -define bmp:subtype=RGB565 {dst}')\n",
    "        os.remove(pth)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ran 565 conversion on {pth} into {dst}\")\n",
    "    return\n",
    "\n",
    "convertTo565(test_apple_dir, \"apple\")\n",
    "convertTo565(test_orange_dir, \"orange\")\n",
    "convertTo565(train_apple_dir, \"apple\")\n",
    "convertTo565(train_orange_dir, \"orange\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Convert images into features np arrays\n",
    "# Also scale X vector\n",
    "\n",
    "\n",
    "test_image = os.path.join(train_apple_dir, \"565-apple-0.jpg\")\n",
    "im = cv2.imread(test_image)\n",
    "features = np.mean(np.mean(im, axis=0), axis=0)\n",
    "features_length = features.shape[0]\n",
    "\n",
    "\n",
    "def get_features(image_dir, label):\n",
    "    # image_dir - image directory\n",
    "    # functions takes in directory of images to generate features using HOG and specified label\n",
    "    # Outputs features, labels\n",
    "    X = np.empty(features_length)\n",
    "    y = int(np.empty(1))\n",
    "    for fl in os.listdir(image_dir):\n",
    "        im = cv2.imread(os.path.join(image_dir, fl))\n",
    "        # features = hog(im, orientations=9, pixels_per_cell=(8,8), cells_per_block=(2,2), multichannel=True)\n",
    "        # print(im.shape)\n",
    "        features_1 = np.mean(im, axis=0)\n",
    "        # print(features_1.shape)\n",
    "        features = np.mean(features_1, axis=0)\n",
    "        # print(features.shape)\n",
    "        X = np.vstack([X, features])\n",
    "        y = np.hstack([y, label])\n",
    "    return X, y\n",
    "\n",
    "trainX, trainY = get_features(train_apple_dir, 0)\n",
    "_X, _y = get_features(train_orange_dir, 1)\n",
    "trainX = np.vstack([trainX, _X])\n",
    "trainY = np.hstack([trainY, _y])\n",
    "\n",
    "print(f\"Dimensions of trainX data: {trainX.shape}\")\n",
    "print(f\"Dimensions of trainY data: {trainY.shape}\")\n",
    "\n",
    "print(f\"NaN check: {np.any(np.isnan(trainX))} (Should be False)\")\n",
    "\n",
    "print(f\"Finite check: {np.all(np.isfinite(trainY))} (Should be True)\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dimensions of trainX data: (960, 3)\n",
      "Dimensions of trainY data: (960,)\n",
      "NaN check: False (Should be False)\n",
      "Finite check: True (Should be True)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "clf = svm.LinearSVC(C=1.)\n",
    "clf.fit(trainX, trainY)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib64/python3.6/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "          verbose=0)"
      ]
     },
     "metadata": {},
     "execution_count": 316
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "testX, testY = get_features(test_apple_dir, 0)\n",
    "__X, __y = get_features(test_orange_dir, 1)\n",
    "testX = np.vstack([testX, __X])\n",
    "testY = np.hstack([testY, __y])\n",
    "\n",
    "clf.score(testX, testY)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9968944099378882"
      ]
     },
     "metadata": {},
     "execution_count": 317
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn_porter import Porter\n",
    "import sys\n",
    "\n",
    "porter = Porter(clf, language='c')\n",
    "c_code = porter.export()\n",
    "original_stdout = sys.stdout\n",
    "with open('model.h', 'w') as f:\n",
    "    sys.stdout = f # Change the standard output to the file we created.\n",
    "    print(c_code)\n",
    "    sys.stdout = original_stdout # Reset the standard output to its original value"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Ignore further cells**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "# # def get_SURF_features(dir):\n",
    "# #     files = os.listdir(dir)\n",
    "# #     for n, fl in enumerate(files):\n",
    "# #         pth = os.path.join(dir, fl)\n",
    "# #         dst = os.path.join(dir, f\"SURF_{fl}\")\n",
    "\n",
    "# #         im = cv2.imread(pth)\n",
    "# #         # im_2 = cv2.cvtColor(im, cv2.COLOR_BGR5652RGB)\n",
    "        \n",
    "# #         if im is None:\n",
    "# #             os.error(\"We have a problem, imread isn't working\")\n",
    "\n",
    "# #         surf = cv2.xfeatures2d.SURF_create(400)\n",
    "# #         keypoints, descriptors = surf.detectAndCompute(im, None)\n",
    "\n",
    "# #         print(len(keypoints))\n",
    "# #         print(descriptors.shape)\n",
    "        \n",
    "# #     return\n",
    "\n",
    "# # get_SURF_features(test_apple_dir)\n",
    "# # get_SURF_features(test_orange_dir)\n",
    "# # get_SURF_features(train_apple_dir)\n",
    "# # get_SURF_features(train_orange_dir)\n",
    "\n",
    "# def get_ORB_features(dir):\n",
    "#     files = os.listdir(dir)\n",
    "#     # combined_data = np.array()\n",
    "\n",
    "#     for n, fl in enumerate(files):\n",
    "#         pth = os.path.join(dir, fl)\n",
    "#         dst = os.path.join(dir, f\"SURF_{fl}\")\n",
    "\n",
    "#         im = cv2.imread(pth)\n",
    "#         # im_2 = cv2.cvtColor(im, cv2.COLOR_BGR5652RGB)\n",
    "        \n",
    "#         if im is None:\n",
    "#             os.error(\"We have a problem, imread isn't working\")\n",
    "\n",
    "#         orb = cv2.ORB_create()\n",
    "#         keypoints, descriptors = orb.detectAndCompute(im, None)\n",
    "\n",
    "#         features = descriptors[:20, :]\n",
    "#         print(features.shape)\n",
    "\n",
    "#         # print(fl)\n",
    "#         # print(descriptors.shape)\n",
    "#         # print(type(descriptors))\n",
    "        \n",
    "#     return\n",
    "\n",
    "# get_ORB_features(test_apple_dir)\n",
    "# get_ORB_features(test_orange_dir)\n",
    "# get_ORB_features(train_apple_dir)\n",
    "# get_ORB_features(train_orange_dir)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import pandas as pd\n",
    "# import csv\n",
    "\n",
    "\n",
    "# # def convertToCSV(dir):\n",
    "# #     files = os.listdir(dir)\n",
    "# #     for n, fl in enumerate(files):\n",
    "# #         pth = os.path.join(dir, fl)\n",
    "# #         print(\"Reading \", pth)\n",
    "# #         dst = os.path.join(dir, f\"CSV_{fl}\")\n",
    "# #         p_csv = pd.read_csv(pth)\n",
    "# #         p_csv.to_csv(dst)\n",
    "\n",
    "# def convertToCSV(dir, fruit):\n",
    "#     files = os.listdir(dir)\n",
    "#     lst = []\n",
    "#     for n, fl in enumerate(files):\n",
    "#         pth = os.path.join(dir, fl)\n",
    "#         # print(\"Reading \", pth)\n",
    "#         p_file = open(pth)\n",
    "#         p_lst = []\n",
    "#         for line in p_file:\n",
    "#             f_line = line[:-2]\n",
    "#             f_line = int(f_line)\n",
    "#             p_lst.append(f_line)\n",
    "#         p_file.close()\n",
    "#         # print(p_lst[:50])\n",
    "#         lst.append(p_lst)\n",
    "#         # print(len(p_lst))\n",
    "#     # print(len(lst))\n",
    "#     dst = os.path.join(TRAIN_DATASET_PATH, f\"{fruit}_out.csv\")\n",
    "#     with open(dst, \"w\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerows(lst)\n",
    "\n",
    "# convertToCSV(train_apple_dir, \"apple\")\n",
    "# convertToCSV(train_orange_dir, \"orange\")\n",
    "\n",
    "        \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_apple = pd.read_csv(os.path.join(TRAIN_DATASET_PATH, \"apple_out.csv\"), header=None)\n",
    "# df_orange = pd.read_csv(os.path.join(TRAIN_DATASET_PATH, \"orange_out.csv\"), header=None)\n",
    "# print(df_apple.shape)\n",
    "# print(df_orange.shape)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from sklearn.svm import SVC\n",
    "# from micromlgen import port\n",
    "# from sklearn_porter import Porter\n",
    "# import sys\n",
    "\n",
    "# def trainClassifier(X, y):\n",
    "#     clf = SVC(kernel='linear',gamma=0.001).fit(X, y)\n",
    "#     return clf\n",
    "\n",
    "# clf = trainClassifier(df_combined.iloc[:, 1:], df_combined.iloc[:, 0])\n",
    "# # c_code = port(clf, classmap={\n",
    "# #         0: 'apple',\n",
    "# #         1: 'orange'\n",
    "# #     })\n",
    "\n",
    "# porter = Porter(clf, language='c')\n",
    "\n",
    "\n",
    "# c_code = porter.export()\n",
    "# # print(c_code)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# porter = Porter(clf, language='c')\n",
    "\n",
    "\n",
    "# c_code = porter.export()\n",
    "# # print(c_code)\n",
    "# original_stdout = sys.stdout\n",
    "# with open('model.h', 'w') as f:\n",
    "#     sys.stdout = f # Change the standard output to the file we created.\n",
    "#     print(c_code)\n",
    "#     sys.stdout = original_stdout # Reset the standard output to its original value\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# from PIL import Image\n",
    "# from scipy import misc\n",
    "# import imageio\n",
    "\n",
    "# def convertBMPToBinaryListHelper(img):\n",
    "#     im = Image.open(img, mode='r')\n",
    "#     pixels = list(im.getdata())\n",
    "#     lst = []\n",
    "#     for pixel in pixels:\n",
    "#         r = pixel[0] & 0b11111111\n",
    "#         g = pixel[1] & 0b11111111\n",
    "#         b = pixel[2] & 0b11111111\n",
    "#         rgb = ((r & 0b11111000) << 8) | ((g & 0b11111100) << 3) | ((b & 0b11100000) >> 3)\n",
    "#         bin_data = bin(rgb)[2:]\n",
    "#         if (len(bin_data) != 16):\n",
    "#             print(\"Error! not 16 bits of data here!\", bin_data)\n",
    "#             print(r, g, b)\n",
    "#             bin_data = bin_data.zfill(16)\n",
    "#             print(f\"Converted to: {bin_data}\")\n",
    "#         # print(bin_data)\n",
    "#         lst.append(bin_data)\n",
    "#     return lst\n",
    "\n",
    "# def convertBMPToBinaryList(dir):\n",
    "#     files = os.listdir(dir)\n",
    "#     for fl in files:\n",
    "#         pth = os.path.join(dir, fl)\n",
    "#         dst = os.path.join(dir, f\"binary-{fl[:-4]}.txt\")\n",
    "#         bin_list = convertBMPToBinaryListHelper(pth)\n",
    "#         dest_file = open(dst, \"w\")\n",
    "#         dest_file.write(str(bin_list))\n",
    "#         print(f\"Converted {pth} to {dst}\")\n",
    "#         os.remove(pth)\n",
    "    \n",
    "\n",
    "# flattened_image = convertBMPToBinaryList(\"model_data/Test/Oranges\")\n",
    "# # test_lst = convertBMPToBinaryListHelper(\"model_data/Test/Oranges/orange8.bmp\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}