{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.8 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "test_apple_dir = \"model_data/Test/Apples\"\n",
    "test_orange_dir = \"model_data/Test/Oranges\"\n",
    "\n",
    "train_apple_dir = \"model_data/Train/Apples\"\n",
    "train_orange_dir = \"model_data/Train/Oranges\"\n",
    "\n",
    "RAW_DATASET_PATH = \"raw_dataset\"\n",
    "RAW_TRAIN_DATASET_PATH = os.path.join(RAW_DATASET_PATH, \"Training\")\n",
    "RAW_TEST_DATASET_PATH = os.path.join(RAW_DATASET_PATH, \"Test\")\n",
    "DATASET_PATH = \"model_data\"\n",
    "TRAIN_DATASET_PATH = os.path.join(DATASET_PATH, \"Train\")\n",
    "TEST_DATASET_PATH = os.path.join(DATASET_PATH, \"Test\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# ONLY RUN CELL IF NEEDED TO CLEAR ALL THE MODEL_DATA\n",
    "print(os.getcwd())\n",
    "\n",
    "if os.path.exists(test_apple_dir):\n",
    "    shutil.rmtree(test_apple_dir)\n",
    "\n",
    "if os.path.exists(test_orange_dir):\n",
    "    shutil.rmtree(test_orange_dir)\n",
    "\n",
    "if os.path.exists(train_apple_dir):\n",
    "    shutil.rmtree(train_apple_dir)\n",
    "\n",
    "if os.path.exists(train_orange_dir):\n",
    "    shutil.rmtree(train_orange_dir)\n",
    "\n",
    "os.mkdir(test_apple_dir)\n",
    "os.mkdir(test_orange_dir)\n",
    "os.mkdir(train_apple_dir)\n",
    "os.mkdir(train_orange_dir)\n",
    "\n",
    "if (os.path.isfile(os.path.join(TRAIN_DATASET_PATH, \"apple_out.csv\"))):\n",
    "    os.remove(os.path.join(TRAIN_DATASET_PATH, \"apple_out.csv\"))\n",
    "\n",
    "if (os.path.isfile(os.path.join(TRAIN_DATASET_PATH, \"orange_out.csv\"))):\n",
    "    os.remove(os.path.join(TRAIN_DATASET_PATH, \"orange_out.csv\"))\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/home/pbhagava/Desktop/EdgeTestbed/edge_testbed/V1/src/sw/test_images\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# For training\n",
    "# Grab 5 Apple images from each type (7*5 = Total 35)\n",
    "NUM_IMAGES_PER_APPLE = 6\n",
    "# Grab 35 Orange Images(Total 35)\n",
    "NUM_IMAGES_PER_ORANGE = NUM_IMAGES_PER_APPLE * 7\n",
    "# Put in model_data/Test or /Training\n",
    "\n",
    "# For testing\n",
    "# Grab 10 apple and 10 orange images (Total 20)\n",
    "NUM_TEST_IMAGES = 28 #Make sure multiple of 14\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def getImages(directory, destination, name, num_files):\n",
    "    files = os.listdir(os.path.join(directory, name))\n",
    "    ret = random.sample(files, num_files)\n",
    "\n",
    "    for file in ret:\n",
    "        path = os.path.join(directory, name, file)\n",
    "        shutil.copy(path, destination)\n",
    "    # print(len(ret))\n",
    "    return ret"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "apple_names = [\"Apple Braeburn\", \"Apple Crimson Snow\", \"Apple Pink Lady\", \"Apple Red 1\", \"Apple Red 2\", \"Apple Red 3\", \"Apple Red Delicious\"]\n",
    "orange_names = [\"Orange\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "apple_train_images = []\n",
    "apple_test_images = []\n",
    "orange_train_images = []\n",
    "orange_test_images = []\n",
    "\n",
    "# Get apple train images\n",
    "for apple_name in apple_names:\n",
    "    apple_train_images.extend(getImages(RAW_TRAIN_DATASET_PATH, TRAIN_DATASET_PATH + \"/Apples\", apple_name, NUM_IMAGES_PER_APPLE))\n",
    "\n",
    "# Get orange train images\n",
    "orange_train_images = getImages(RAW_TRAIN_DATASET_PATH, TRAIN_DATASET_PATH + \"/Oranges\", \"Orange\", NUM_IMAGES_PER_ORANGE)\n",
    "\n",
    "# Get apple test images\n",
    "for apple_name in apple_names:\n",
    "    apple_test_images.extend(getImages(RAW_TEST_DATASET_PATH, TEST_DATASET_PATH + \"/Apples\", apple_name, NUM_TEST_IMAGES//2//7))\n",
    "\n",
    "# Get orange test images\n",
    "orange_test_images = getImages(RAW_TEST_DATASET_PATH, TEST_DATASET_PATH + \"/Oranges\", \"Orange\", NUM_TEST_IMAGES//2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "print(len(orange_test_images))\n",
    "print(len(apple_test_images))\n",
    "print(len(orange_train_images))\n",
    "print(len(apple_train_images))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "14\n",
      "14\n",
      "42\n",
      "42\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# Upscale/Rescale Images to 320x240\n",
    "def convertTo320x240(dir):\n",
    "    files = os.listdir(dir)\n",
    "    for n, fl in enumerate(files):\n",
    "        pth = os.path.join(dir, fl)\n",
    "        dst = os.path.join(dir, f\"resized-{fl}\")\n",
    "        os.system(f\"convert {pth} -resize 320x240\\! {dst}\")\n",
    "        os.remove(pth)\n",
    "        print(f\"ran convert {pth} -resize 320x240\\! {dst}\")\n",
    "    return\n",
    "\n",
    "convertTo320x240(test_apple_dir)\n",
    "convertTo320x240(test_orange_dir)\n",
    "convertTo320x240(train_apple_dir)\n",
    "convertTo320x240(train_orange_dir)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ran convert model_data/Test/Apples/r_92_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_92_100.jpg\n",
      "ran convert model_data/Test/Apples/r_90_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_90_100.jpg\n",
      "ran convert model_data/Test/Apples/95_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-95_100.jpg\n",
      "ran convert model_data/Test/Apples/r_39_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_39_100.jpg\n",
      "ran convert model_data/Test/Apples/r_268_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_268_100.jpg\n",
      "ran convert model_data/Test/Apples/262_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-262_100.jpg\n",
      "ran convert model_data/Test/Apples/r_91_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_91_100.jpg\n",
      "ran convert model_data/Test/Apples/r_94_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_94_100.jpg\n",
      "ran convert model_data/Test/Apples/r_59_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_59_100.jpg\n",
      "ran convert model_data/Test/Apples/44_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-44_100.jpg\n",
      "ran convert model_data/Test/Apples/r_83_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_83_100.jpg\n",
      "ran convert model_data/Test/Apples/r_326_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_326_100.jpg\n",
      "ran convert model_data/Test/Apples/r_6_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-r_6_100.jpg\n",
      "ran convert model_data/Test/Apples/179_100.jpg -resize 320x240\\! model_data/Test/Apples/resized-179_100.jpg\n",
      "ran convert model_data/Test/Oranges/83_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-83_100.jpg\n",
      "ran convert model_data/Test/Oranges/66_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-66_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_39_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_39_100.jpg\n",
      "ran convert model_data/Test/Oranges/57_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-57_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_99_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_99_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_86_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_86_100.jpg\n",
      "ran convert model_data/Test/Oranges/93_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-93_100.jpg\n",
      "ran convert model_data/Test/Oranges/36_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-36_100.jpg\n",
      "ran convert model_data/Test/Oranges/9_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-9_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_92_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_92_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_49_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_49_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_41_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_41_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_60_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_60_100.jpg\n",
      "ran convert model_data/Test/Oranges/r_65_100.jpg -resize 320x240\\! model_data/Test/Oranges/resized-r_65_100.jpg\n",
      "ran convert model_data/Train/Apples/r_11_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_11_100.jpg\n",
      "ran convert model_data/Train/Apples/r_132_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_132_100.jpg\n",
      "ran convert model_data/Train/Apples/r_230_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_230_100.jpg\n",
      "ran convert model_data/Train/Apples/107_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-107_100.jpg\n",
      "ran convert model_data/Train/Apples/r_292_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_292_100.jpg\n",
      "ran convert model_data/Train/Apples/200_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-200_100.jpg\n",
      "ran convert model_data/Train/Apples/214_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-214_100.jpg\n",
      "ran convert model_data/Train/Apples/165_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-165_100.jpg\n",
      "ran convert model_data/Train/Apples/67_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-67_100.jpg\n",
      "ran convert model_data/Train/Apples/31_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-31_100.jpg\n",
      "ran convert model_data/Train/Apples/186_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-186_100.jpg\n",
      "ran convert model_data/Train/Apples/r_77_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_77_100.jpg\n",
      "ran convert model_data/Train/Apples/127_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-127_100.jpg\n",
      "ran convert model_data/Train/Apples/224_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-224_100.jpg\n",
      "ran convert model_data/Train/Apples/36_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-36_100.jpg\n",
      "ran convert model_data/Train/Apples/47_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-47_100.jpg\n",
      "ran convert model_data/Train/Apples/r_120_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_120_100.jpg\n",
      "ran convert model_data/Train/Apples/r_263_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_263_100.jpg\n",
      "ran convert model_data/Train/Apples/r_257_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_257_100.jpg\n",
      "ran convert model_data/Train/Apples/r_302_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_302_100.jpg\n",
      "ran convert model_data/Train/Apples/121_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-121_100.jpg\n",
      "ran convert model_data/Train/Apples/256_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-256_100.jpg\n",
      "ran convert model_data/Train/Apples/r_160_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_160_100.jpg\n",
      "ran convert model_data/Train/Apples/r_203_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_203_100.jpg\n",
      "ran convert model_data/Train/Apples/r_20_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_20_100.jpg\n",
      "ran convert model_data/Train/Apples/164_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-164_100.jpg\n",
      "ran convert model_data/Train/Apples/307_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-307_100.jpg\n",
      "ran convert model_data/Train/Apples/161_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-161_100.jpg\n",
      "ran convert model_data/Train/Apples/195_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-195_100.jpg\n",
      "ran convert model_data/Train/Apples/r_255_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_255_100.jpg\n",
      "ran convert model_data/Train/Apples/24_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-24_100.jpg\n",
      "ran convert model_data/Train/Apples/174_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-174_100.jpg\n",
      "ran convert model_data/Train/Apples/199_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-199_100.jpg\n",
      "ran convert model_data/Train/Apples/169_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-169_100.jpg\n",
      "ran convert model_data/Train/Apples/111_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-111_100.jpg\n",
      "ran convert model_data/Train/Apples/r_243_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_243_100.jpg\n",
      "ran convert model_data/Train/Apples/r_87_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_87_100.jpg\n",
      "ran convert model_data/Train/Apples/r_24_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-r_24_100.jpg\n",
      "ran convert model_data/Train/Apples/101_100.jpg -resize 320x240\\! model_data/Train/Apples/resized-101_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_176_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_176_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_135_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_135_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_251_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_251_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_29_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_29_100.jpg\n",
      "ran convert model_data/Train/Oranges/213_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-213_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_173_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_173_100.jpg\n",
      "ran convert model_data/Train/Oranges/211_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-211_100.jpg\n",
      "ran convert model_data/Train/Oranges/264_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-264_100.jpg\n",
      "ran convert model_data/Train/Oranges/121_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-121_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_21_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_21_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_174_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_174_100.jpg\n",
      "ran convert model_data/Train/Oranges/115_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-115_100.jpg\n",
      "ran convert model_data/Train/Oranges/195_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-195_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_106_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_106_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_101_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_101_100.jpg\n",
      "ran convert model_data/Train/Oranges/250_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-250_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_284_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_284_100.jpg\n",
      "ran convert model_data/Train/Oranges/148_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-148_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_20_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_20_100.jpg\n",
      "ran convert model_data/Train/Oranges/17_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-17_100.jpg\n",
      "ran convert model_data/Train/Oranges/229_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-229_100.jpg\n",
      "ran convert model_data/Train/Oranges/158_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-158_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_292_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_292_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_146_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_146_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_168_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_168_100.jpg\n",
      "ran convert model_data/Train/Oranges/246_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-246_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_318_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_318_100.jpg\n",
      "ran convert model_data/Train/Oranges/120_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-120_100.jpg\n",
      "ran convert model_data/Train/Oranges/124_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-124_100.jpg\n",
      "ran convert model_data/Train/Oranges/214_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-214_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_304_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_304_100.jpg\n",
      "ran convert model_data/Train/Oranges/238_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-238_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_262_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_262_100.jpg\n",
      "ran convert model_data/Train/Oranges/197_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-197_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_187_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_187_100.jpg\n",
      "ran convert model_data/Train/Oranges/298_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-298_100.jpg\n",
      "ran convert model_data/Train/Oranges/164_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-164_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_212_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_212_100.jpg\n",
      "ran convert model_data/Train/Oranges/141_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-141_100.jpg\n",
      "ran convert model_data/Train/Oranges/224_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-224_100.jpg\n",
      "ran convert model_data/Train/Oranges/308_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-308_100.jpg\n",
      "ran convert model_data/Train/Oranges/r_108_100.jpg -resize 320x240\\! model_data/Train/Oranges/resized-r_108_100.jpg\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "str_ = 'ffmpeg -i converted-230_100.jpg -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e \\'1/2 \"%u \" \"\\\\n\"\\' -v > test.txt'\n",
    "print(str_)\n",
    "\n",
    "# ffmpeg -i converted-230_100.jpg -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e '1/2 \"%u \" \"\\n\"' -v > test.txt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ffmpeg -i converted-230_100.jpg -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e '1/2 \"%u \" \"\\n\"' -v > test.txt\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Convert to bitstream\n",
    "\n",
    "\n",
    "\n",
    "# def convertTo565(dir, fruit, to_csv=False):\n",
    "#     files = os.listdir(dir)\n",
    "#     for n, fl in enumerate(files):\n",
    "#         pth = os.path.join(dir, fl)\n",
    "#         dst = os.path.join(dir, f\"565-{fruit}-{n}.txt\")\n",
    "#         if (to_csv):\n",
    "#             os.system(f'ffmpeg -i {pth} -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e \\'1/2 \"%u\" \", \"\\' -v > {dst}')\n",
    "#             os.remove(pth)\n",
    "#         else:\n",
    "#             os.system(f'ffmpeg -i {pth} -vcodec rawvideo -f rawvideo -pix_fmt rgb565 pipe:1 | hexdump -e \\'1/2 \"%u \" \"\\\\n\"\\' -v > {dst}')\n",
    "#             os.remove(pth)\n",
    "#         print(f\"ran bitstream conversion on {pth} into {dst}\")\n",
    "#     return\n",
    "\n",
    "def convertTo565(dir, fruit, to_csv=False):\n",
    "    files = os.listdir(dir)\n",
    "    for n, fl in enumerate(files):\n",
    "        pth = os.path.join(dir, fl)\n",
    "        dst = os.path.join(dir, f\"565-{fruit}-{n}.bmp\")\n",
    "        \n",
    "        os.system(f'convert {pth} -define bmp:subtype=RGB565 {dst}')\n",
    "        os.remove(pth)\n",
    "\n",
    "        print(f\"ran 565 conversion on {pth} into {dst}\")\n",
    "    return\n",
    "\n",
    "convertTo565(test_apple_dir, \"apple\")\n",
    "convertTo565(test_orange_dir, \"orange\")\n",
    "convertTo565(train_apple_dir, \"apple\")\n",
    "convertTo565(train_orange_dir, \"orange\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ran 565 conversion on model_data/Test/Apples/resized-r_92_100.jpg into model_data/Test/Apples/565-apple-0.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_90_100.jpg into model_data/Test/Apples/565-apple-1.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-95_100.jpg into model_data/Test/Apples/565-apple-2.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_39_100.jpg into model_data/Test/Apples/565-apple-3.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_268_100.jpg into model_data/Test/Apples/565-apple-4.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-262_100.jpg into model_data/Test/Apples/565-apple-5.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_91_100.jpg into model_data/Test/Apples/565-apple-6.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_94_100.jpg into model_data/Test/Apples/565-apple-7.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_59_100.jpg into model_data/Test/Apples/565-apple-8.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-44_100.jpg into model_data/Test/Apples/565-apple-9.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_83_100.jpg into model_data/Test/Apples/565-apple-10.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_326_100.jpg into model_data/Test/Apples/565-apple-11.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-r_6_100.jpg into model_data/Test/Apples/565-apple-12.bmp\n",
      "ran 565 conversion on model_data/Test/Apples/resized-179_100.jpg into model_data/Test/Apples/565-apple-13.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-83_100.jpg into model_data/Test/Oranges/565-orange-0.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-66_100.jpg into model_data/Test/Oranges/565-orange-1.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_39_100.jpg into model_data/Test/Oranges/565-orange-2.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-57_100.jpg into model_data/Test/Oranges/565-orange-3.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_99_100.jpg into model_data/Test/Oranges/565-orange-4.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_86_100.jpg into model_data/Test/Oranges/565-orange-5.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-93_100.jpg into model_data/Test/Oranges/565-orange-6.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-36_100.jpg into model_data/Test/Oranges/565-orange-7.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-9_100.jpg into model_data/Test/Oranges/565-orange-8.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_92_100.jpg into model_data/Test/Oranges/565-orange-9.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_49_100.jpg into model_data/Test/Oranges/565-orange-10.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_41_100.jpg into model_data/Test/Oranges/565-orange-11.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_60_100.jpg into model_data/Test/Oranges/565-orange-12.bmp\n",
      "ran 565 conversion on model_data/Test/Oranges/resized-r_65_100.jpg into model_data/Test/Oranges/565-orange-13.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_11_100.jpg into model_data/Train/Apples/565-apple-0.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_132_100.jpg into model_data/Train/Apples/565-apple-1.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_230_100.jpg into model_data/Train/Apples/565-apple-2.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-107_100.jpg into model_data/Train/Apples/565-apple-3.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_292_100.jpg into model_data/Train/Apples/565-apple-4.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-200_100.jpg into model_data/Train/Apples/565-apple-5.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-214_100.jpg into model_data/Train/Apples/565-apple-6.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-165_100.jpg into model_data/Train/Apples/565-apple-7.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-67_100.jpg into model_data/Train/Apples/565-apple-8.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-31_100.jpg into model_data/Train/Apples/565-apple-9.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-186_100.jpg into model_data/Train/Apples/565-apple-10.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_77_100.jpg into model_data/Train/Apples/565-apple-11.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-127_100.jpg into model_data/Train/Apples/565-apple-12.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-224_100.jpg into model_data/Train/Apples/565-apple-13.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-36_100.jpg into model_data/Train/Apples/565-apple-14.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-47_100.jpg into model_data/Train/Apples/565-apple-15.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_120_100.jpg into model_data/Train/Apples/565-apple-16.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_263_100.jpg into model_data/Train/Apples/565-apple-17.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_257_100.jpg into model_data/Train/Apples/565-apple-18.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_302_100.jpg into model_data/Train/Apples/565-apple-19.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-121_100.jpg into model_data/Train/Apples/565-apple-20.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-256_100.jpg into model_data/Train/Apples/565-apple-21.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_160_100.jpg into model_data/Train/Apples/565-apple-22.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_203_100.jpg into model_data/Train/Apples/565-apple-23.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_20_100.jpg into model_data/Train/Apples/565-apple-24.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-164_100.jpg into model_data/Train/Apples/565-apple-25.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-307_100.jpg into model_data/Train/Apples/565-apple-26.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-161_100.jpg into model_data/Train/Apples/565-apple-27.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-195_100.jpg into model_data/Train/Apples/565-apple-28.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_255_100.jpg into model_data/Train/Apples/565-apple-29.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-24_100.jpg into model_data/Train/Apples/565-apple-30.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-174_100.jpg into model_data/Train/Apples/565-apple-31.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-199_100.jpg into model_data/Train/Apples/565-apple-32.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-169_100.jpg into model_data/Train/Apples/565-apple-33.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-111_100.jpg into model_data/Train/Apples/565-apple-34.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_243_100.jpg into model_data/Train/Apples/565-apple-35.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_87_100.jpg into model_data/Train/Apples/565-apple-36.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-r_24_100.jpg into model_data/Train/Apples/565-apple-37.bmp\n",
      "ran 565 conversion on model_data/Train/Apples/resized-101_100.jpg into model_data/Train/Apples/565-apple-38.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-308_100.jpg into model_data/Train/Oranges/565-orange-0.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_176_100.jpg into model_data/Train/Oranges/565-orange-1.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_135_100.jpg into model_data/Train/Oranges/565-orange-2.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_251_100.jpg into model_data/Train/Oranges/565-orange-3.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_29_100.jpg into model_data/Train/Oranges/565-orange-4.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-213_100.jpg into model_data/Train/Oranges/565-orange-5.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_173_100.jpg into model_data/Train/Oranges/565-orange-6.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-211_100.jpg into model_data/Train/Oranges/565-orange-7.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-264_100.jpg into model_data/Train/Oranges/565-orange-8.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-121_100.jpg into model_data/Train/Oranges/565-orange-9.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_21_100.jpg into model_data/Train/Oranges/565-orange-10.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_174_100.jpg into model_data/Train/Oranges/565-orange-11.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-115_100.jpg into model_data/Train/Oranges/565-orange-12.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-195_100.jpg into model_data/Train/Oranges/565-orange-13.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_106_100.jpg into model_data/Train/Oranges/565-orange-14.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_101_100.jpg into model_data/Train/Oranges/565-orange-15.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-250_100.jpg into model_data/Train/Oranges/565-orange-16.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_284_100.jpg into model_data/Train/Oranges/565-orange-17.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-148_100.jpg into model_data/Train/Oranges/565-orange-18.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_20_100.jpg into model_data/Train/Oranges/565-orange-19.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-17_100.jpg into model_data/Train/Oranges/565-orange-20.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-229_100.jpg into model_data/Train/Oranges/565-orange-21.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-158_100.jpg into model_data/Train/Oranges/565-orange-22.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_292_100.jpg into model_data/Train/Oranges/565-orange-23.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_146_100.jpg into model_data/Train/Oranges/565-orange-24.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_168_100.jpg into model_data/Train/Oranges/565-orange-25.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-246_100.jpg into model_data/Train/Oranges/565-orange-26.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_318_100.jpg into model_data/Train/Oranges/565-orange-27.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-120_100.jpg into model_data/Train/Oranges/565-orange-28.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-124_100.jpg into model_data/Train/Oranges/565-orange-29.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-214_100.jpg into model_data/Train/Oranges/565-orange-30.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_304_100.jpg into model_data/Train/Oranges/565-orange-31.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-238_100.jpg into model_data/Train/Oranges/565-orange-32.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_262_100.jpg into model_data/Train/Oranges/565-orange-33.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-197_100.jpg into model_data/Train/Oranges/565-orange-34.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_187_100.jpg into model_data/Train/Oranges/565-orange-35.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-298_100.jpg into model_data/Train/Oranges/565-orange-36.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-164_100.jpg into model_data/Train/Oranges/565-orange-37.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_212_100.jpg into model_data/Train/Oranges/565-orange-38.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-141_100.jpg into model_data/Train/Oranges/565-orange-39.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-224_100.jpg into model_data/Train/Oranges/565-orange-40.bmp\n",
      "ran 565 conversion on model_data/Train/Oranges/resized-r_108_100.jpg into model_data/Train/Oranges/565-orange-41.bmp\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import cv2\n",
    "\n",
    "def get_SURF_features(dir):\n",
    "    files = os.listdir(dir)\n",
    "    for n, fl in enumerate(files):\n",
    "        pth = os.path.join(dir, fl)\n",
    "        dst = os.path.join(dir, f\"SURF_{fl}\")\n",
    "\n",
    "        im = cv2.imread(pth)\n",
    "        \n",
    "        surf = cv2.xfeatures2.SURF_create(hessian_threshold=500)\n",
    "        keypoints, descriptors = surf.detectAndCompute(im, None)\n",
    "\n",
    "        print(descriptors.shape)\n",
    "        \n",
    "    return\n",
    "\n",
    "get_SURF_features(test_apple_dir)\n",
    "get_SURF_features(test_orange_dir)\n",
    "get_SURF_features(train_apple_dir)\n",
    "get_SURF_features(train_orange_dir)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'xfeatures2'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-e332b17ff402>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mget_SURF_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_apple_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mget_SURF_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_orange_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mget_SURF_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_apple_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-e332b17ff402>\u001b[0m in \u001b[0;36mget_SURF_features\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0msurf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxfeatures2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSURF_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessian_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mkeypoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescriptors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'xfeatures2'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "# def convertToCSV(dir):\n",
    "#     files = os.listdir(dir)\n",
    "#     for n, fl in enumerate(files):\n",
    "#         pth = os.path.join(dir, fl)\n",
    "#         print(\"Reading \", pth)\n",
    "#         dst = os.path.join(dir, f\"CSV_{fl}\")\n",
    "#         p_csv = pd.read_csv(pth)\n",
    "#         p_csv.to_csv(dst)\n",
    "\n",
    "def convertToCSV(dir, fruit):\n",
    "    files = os.listdir(dir)\n",
    "    lst = []\n",
    "    for n, fl in enumerate(files):\n",
    "        pth = os.path.join(dir, fl)\n",
    "        # print(\"Reading \", pth)\n",
    "        p_file = open(pth)\n",
    "        p_lst = []\n",
    "        for line in p_file:\n",
    "            f_line = line[:-2]\n",
    "            f_line = int(f_line)\n",
    "            p_lst.append(f_line)\n",
    "        p_file.close()\n",
    "        # print(p_lst[:50])\n",
    "        lst.append(p_lst)\n",
    "        # print(len(p_lst))\n",
    "    # print(len(lst))\n",
    "    dst = os.path.join(TRAIN_DATASET_PATH, f\"{fruit}_out.csv\")\n",
    "    with open(dst, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(lst)\n",
    "\n",
    "convertToCSV(train_apple_dir, \"apple\")\n",
    "convertToCSV(train_orange_dir, \"orange\")\n",
    "\n",
    "        \n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'train_apple_dir' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-51cb69075891>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mconvertToCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_apple_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"apple\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mconvertToCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_orange_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"orange\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_apple_dir' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_apple = pd.read_csv(os.path.join(TRAIN_DATASET_PATH, \"apple_out.csv\"), header=None)\n",
    "df_orange = pd.read_csv(os.path.join(TRAIN_DATASET_PATH, \"orange_out.csv\"), header=None)\n",
    "print(df_apple.shape)\n",
    "print(df_orange.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(42, 76800)\n",
      "(42, 76800)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "df_apple.insert(0, \"fruit\", 0)\n",
    "df_orange.insert(0, \"fruit\", 1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(df_apple.shape)\n",
    "print(df_orange.shape)\n",
    "\n",
    "df_combined = pd.concat([df_apple, df_orange])\n",
    "print(df_combined.shape)\n",
    "print(df_combined.iloc[:, 0])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(42, 76801)\n",
      "(42, 76801)\n",
      "(84, 76801)\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "     ..\n",
      "37    1\n",
      "38    1\n",
      "39    1\n",
      "40    1\n",
      "41    1\n",
      "Name: fruit, Length: 84, dtype: int64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "from sklearn.svm import SVC\n",
    "from micromlgen import port\n",
    "from sklearn_porter import Porter\n",
    "import sys\n",
    "\n",
    "def trainClassifier(X, y):\n",
    "    clf = SVC(kernel='linear',gamma=0.001).fit(X, y)\n",
    "    return clf\n",
    "\n",
    "clf = trainClassifier(df_combined.iloc[:, 1:], df_combined.iloc[:, 0])\n",
    "# c_code = port(clf, classmap={\n",
    "#         0: 'apple',\n",
    "#         1: 'orange'\n",
    "#     })\n",
    "\n",
    "porter = Porter(clf, language='c')\n",
    "\n",
    "\n",
    "c_code = porter.export()\n",
    "# print(c_code)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "original_stdout = sys.stdout\n",
    "with open('model.h', 'w') as f:\n",
    "    sys.stdout = f # Change the standard output to the file we created.\n",
    "    print(c_code)\n",
    "    sys.stdout = original_stdout # Reset the standard output to its original value\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# from PIL import Image\n",
    "# from scipy import misc\n",
    "# import imageio\n",
    "\n",
    "# def convertBMPToBinaryListHelper(img):\n",
    "#     im = Image.open(img, mode='r')\n",
    "#     pixels = list(im.getdata())\n",
    "#     lst = []\n",
    "#     for pixel in pixels:\n",
    "#         r = pixel[0] & 0b11111111\n",
    "#         g = pixel[1] & 0b11111111\n",
    "#         b = pixel[2] & 0b11111111\n",
    "#         rgb = ((r & 0b11111000) << 8) | ((g & 0b11111100) << 3) | ((b & 0b11100000) >> 3)\n",
    "#         bin_data = bin(rgb)[2:]\n",
    "#         if (len(bin_data) != 16):\n",
    "#             print(\"Error! not 16 bits of data here!\", bin_data)\n",
    "#             print(r, g, b)\n",
    "#             bin_data = bin_data.zfill(16)\n",
    "#             print(f\"Converted to: {bin_data}\")\n",
    "#         # print(bin_data)\n",
    "#         lst.append(bin_data)\n",
    "#     return lst\n",
    "\n",
    "# def convertBMPToBinaryList(dir):\n",
    "#     files = os.listdir(dir)\n",
    "#     for fl in files:\n",
    "#         pth = os.path.join(dir, fl)\n",
    "#         dst = os.path.join(dir, f\"binary-{fl[:-4]}.txt\")\n",
    "#         bin_list = convertBMPToBinaryListHelper(pth)\n",
    "#         dest_file = open(dst, \"w\")\n",
    "#         dest_file.write(str(bin_list))\n",
    "#         print(f\"Converted {pth} to {dst}\")\n",
    "#         os.remove(pth)\n",
    "    \n",
    "\n",
    "# flattened_image = convertBMPToBinaryList(\"model_data/Test/Oranges\")\n",
    "# # test_lst = convertBMPToBinaryListHelper(\"model_data/Test/Oranges/orange8.bmp\")"
   ],
   "outputs": [],
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}